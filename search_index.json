[
["index.html", "DHSC Coding Principles Disclaimer", " DHSC Coding Principles Matthew Malcher Disclaimer This is an unapproved draft and does not represent the views of the DHSC. "],
["introduction.html", "Introduction", " Introduction These principles are designed with the aim of improving coding standards and consistency within the department. Adoption of these principles should improve quality, facilitate collaboration and enable effective QA of code. The principles are not language specific. This is to maximise uptake and provide a uniform set of values across languages. The principles are designed to be achievable by all DHSC analysts producing code. Each Principle is flexible and has multiple levels: Must - You aren’t finished until your code has met this standard. Should - Do this unless you are ready to justify not doing so. Could - Things you can do to improve your code beyond the base standard. "],
["overview.html", "Overview", " Overview 1) Use Version Control Version control your code so you and your collaborators can track changes over time, trace back errors, and retrieve old versions. Version control will help you make changes and improvements to your code with confidence. 2) Write Easy to Read Code Keep your code easy to read. Using a consistent style and sensible names will make it easier to collaborate and quality assure work. It will also help you spot errors. 3) Correct, Clear, Fast &amp; Concise - In That Order Write code with your colleagues priorities in mind. They need your code to work correctly, and they will have to understand and check it before they can benefit from it being fast or concise. 4) Write Flexible Code Write flexible code where it will save time later. Good code is often adapted and repurposed. However, don’t try to solve every problem upfront, or try and cover edge cases you may never encounter. Find a balance and focus on making your code easy to change. 5) Comment Effectively Comment your code so that it’s function is clear. Well targeted comments make it less likely that avoidable mistakes are made when using or updating your code. Colleagues and your future self will thank you. 6) Document Your Work Maintain documentation for your code. Code is not self documenting and code without documentation won’t be useful later. You need to capture higher level context such as what the code is for, why it is written a certain way and what the inputs and outputs are. 7) Be Demonstrably Correct Have a clear and robust way to demonstrate your code is correct. We need to be confident in the outputs we provide. Just because something is done with code doesn’t make it immune from answering the wrong question, using the wrong inputs, or doing the calculation incorrectly. 8) Use Sensible Defaults Do common tasks in a consistent way, following guidance. If we use the same tools and approaches across the department, it makes collaboration and quality assurance easier. This is almost always more important than using the absolute best method. 9) Be Reproducible Work in a way which is reproducible. Within the department, analysis is used to enable evidence based decision making. A piece of evidence which you cannot rely on being able to reproduce is not much good. There are many reproducibility pitfalls and it is our responsibility to overcome them. 10) Use Appropriate and Tidy Data Use the right data structures for the job. Programming languages offer many different ways to work with the same data. Using the right one will make a task easier, and decrease your chance of getting it wrong. "],
["summary-table.html", "Summary Table", " Summary Table Principle You Must You Should You Could Use Version Control Use version control and follow guidance on coding in the open. Use standard tools (Git &amp; GitHub) to help you version control code. Use (Git &amp; GitHub) collaboratively and effectively and agree a version control pattern with your team. Write Easy to Read Code Follow the DHSC adopted style for your language, use meaningful names and avoid overlaps. Use a linter or code formatter to ensure that your code conforms to the style guide. Review your code with colleagues to make ensure your names and style promote understanding. Correct, Clear, Fast &amp; Concise - In That Order Ensure that your code is correct and clear in its function. Make your code fast and concise, where this is possible without sacrificing correctness, clarity or excessive resource! Document the design choices you have made to achieve this balance. Use profiling tools to understand resource usage and refactor to improve clarity and performance. Write Flexible Code Break up your code into chunks, with a clear structure and don’t repeat yourself. Think about, and document the way your code might break with different inputs. Include input validation to catch mistakes earlier in your code and make it easier to repurpose. Implement and test thorough error handling. Consider writing and sharing general purposes ‘tool’ code, especially if you solve a problem someone else might have. Comment Effectively Write and maintain accurate comments as you code. Think carefully about why you are leaving comments, what to capture, and what belongs elsewhere (in documentation). Review old code you have written - are the comments helpful? What would you include next time? Document Your Work Produce documentation in line with Aqua book guidance. Assemble documentation as you code. Use document generation tools to produce documentation. Be Demonstrably Correct Hold your code to the same standard as any other analysis and record evidence demonstrating it produces the right output. Use version control to unambiguously link QA to code and outputs and construct automated tests to provide confidence that changes don’t break things. Make a fully automated reproducible analytical pipeline (RAP) which incorporates checks and validation and minimises opportunity for human error. Use Sensible Defaults Be aware of the defaults, understand why we have them and follow them unless you can explain how the benefits of an alternative approach outweigh those of consistency. Help define what the defaults should be, and actively participate in discussion and debate to keep them up to date and relevant. Proactively review and compare the defaults used with the way you work. Be Reproducible Keep track of what you have done and document it unambiguously so that someone else can recreate it. Write portable code, in a standard project structure so that it is easy for someone else to run it. Turn your code into a package / library / module, learn and promote RAP techniques, or use containers to achieve reproducibility. Use Appropriate and Tidy Data Know what ‘Tidy Data’ is, and understand why it is valuable. Be familiar with the data types and structures available to you and ensure that you use the right ones. Think about relationships between datasets, design schemas and store data in an efficient way. "],
["version-control.html", "Principle 1 Use Version Control 1.1 What is version control? 1.2 Git - (program for version control) 1.3 GitHub - (service for storing code version controlled using git) 1.4 Using Git &amp; GitHub Effectively 1.5 Code in the Open 1.6 Manual Version Control 1.7 Git &amp; GitHub at DHSC 1.8 Useful git resources", " Principle 1 Use Version Control Version control your code so you and your collaborators can track changes over time, trace back errors, and retrieve old versions. Version control will help you make changes and improvements to your code with confidence. You Must - Use version control and follow guidance on coding in the open. You Should - Use standard tools (Git &amp; GitHub) to help you version control code. You Could - Use (Git &amp; GitHub) collaboratively and effectively and agree a version control pattern with your team. Related Areas: Demonstrably Correct, Be Reproducible 1.1 What is version control? Version control is managing changes to the documents and files which make up your work. This typically includes a system for identifying versions (i.e. a version number or name) and some sort of log of what the changes are, who made them and when they were made. Version control systems are usually associated with tools for comparing, restoring and merging versions. 1.2 Git - (program for version control) Git is the most popular way to version control code. You can tell Git to keep track of a folder full of code (a repository or ‘repo’). As you make changes, Git identifies them and asks which should be kept (or ‘committed’), and for a comment identifying why. It uses this to maintain a log of all the changes. This log can be used to restore old versions. 1.3 GitHub - (service for storing code version controlled using git) GitHub is the most popular place to store git repositories. Storing your repository on GitHub has some key benefits: It acts as a backup of your code &amp; its history Other people can see your code, download it and collaborate with you. As such, using a service like GitHub is a good way to ensure that your code is available to your team, and that knowledge is transferred. 1.4 Using Git &amp; GitHub Effectively To make effective use of Git and GitHub: Follow the GDS Git Style Guide Commit code in small chunks, as often as possible, and write a descriptive comment with each commit. This makes your repository much more useful in the future and is called doing ‘atomic commits’. Commit changes using an account which is specific to you so that it is clear in future who changed what. Define a version control pattern which explains how you use git as a team. This could include how you use branches, how you merge changes and how to handle pull requests. 1.5 Code in the Open GitHub repositories can be open (shared with anyone) or private (shared only with selected collaborators). The Technology Code of Practice encourages us to ‘be open and use open source’. As such, code should be open unless there is a good reason for it not to be. Good reasons for code to be private might be that it includes classified material, or information on an unreleased policy. GDS have published guidance on this for both external, and internal use. 1.6 Manual Version Control It is possible to manually keep track of your code by systematically keeping copies of your code as you modify it and maintaining a corresponding log of all changes to the code. The log should include: What has changed, why, and a link to the relevant copy of the files. It is recommended to use version control tools (git) instead of this manual process. 1.7 Git &amp; GitHub at DHSC At present, DHSC base machines do not have git. If you have access to a developer account you can install git for windows from: git-scm.com It is anticipated that in the near future TAP (The Analytical Platform) will provide git functionality for all analysts within the department. 1.8 Useful git resources happygitwithr "],
["easy-to-read.html", "Principle 2 Write Easy to Read Code 2.1 Style Guides 2.2 Linters &amp; Code Formatters 2.3 Meaningful Names 2.4 Avoid Overlaps 2.5 Name Formats", " Principle 2 Write Easy to Read Code Keep your code easy to read. Using a consistent style and sensible names will make it easier to collaborate and quality assure work. It will also help you spot errors. You Must - Follow the DHSC adopted style for your language, use meaningful names and avoid overlaps. You Should - Use a linter or code formatter to ensure that your code conforms to the style guide. You Could - Review your code with colleagues to make ensure your names and style promote understanding. Related Areas: Comments Flexible Code Documentation 2.1 Style Guides Most languages have several available style guides, which define a set of conventions to produce clean and consistently formatted code. Your style guide will define things like: How to use indentation and spacing Line length Add comment blocks at the start of your code Favour named indexes and iterators DHSC has adopted a single style guide for each language. Please use this style; consistency will make it easier for colleagues to understand, QA and improve your code! Language DHSC Adopted Style Guide R tidyverse style guide Python PEP-8 2.2 Linters &amp; Code Formatters Linters are tools that you can use to ensure that you are following a given style guide. Language DHSC Recommended Linter R Styler Python Black 2.3 Meaningful Names Names convey meaning, naming functions &amp; variables well can remove the need for a comment and make life easier for other readers. This includes your future self! Find a balance: avoid meaningless names like obj or foo; but don’t put an entire sentence in a variable name. Use single-letter variables only where the use or meaning is clear - such as an iterator for a loop, or where the letter represents a well-known mathematical property (think: \\(e = mc^2\\)). 2.4 Avoid Overlaps When naming things be wary of overlapping with other meanings. In one context, using \\(e\\) for energy or \\(i\\) for an iterator might be sensible, but in another context might be confused with \\(e\\) for exponent and \\(i\\) for imaginary as in: \\(e^{iθ} = cos(θ) + i sin(θ)\\). Be conscious of overlapping names with things which are parts of the language, or popular functions. For example in Python, you probably want to avoid common abbreviated library names (np or pd), or in R be careful about overwriting things like c which is the name of the function used to make a vector. 2.5 Name Formats Follow your style guide and format your names consistently (i.e. using camelCase or snake_case). "],
["correct-clear-concise.html", "Principle 3 Correct, Clear, Fast &amp; Concise - In That Order 3.1 Correct 3.2 Clear 3.3 Fast 3.4 Concise", " Principle 3 Correct, Clear, Fast &amp; Concise - In That Order Write code with your colleagues priorities in mind. They need your code to work correctly, and they will have to understand and check it before they can benefit from it being fast or concise. You Must - Ensure that your code is correct and clear in its function. You Should - Make your code fast and concise, where this is possible without sacrificing correctness, clarity or excessive resource! Document the design choices you have made to achieve this balance. You Could - Use profiling tools to understand resource usage and refactor to improve clarity and performance. Related Areas: Demonstrably Correct Easy to Read Code Comments 3.1 Correct The first priority should always be that the code is correct. See the demonstably correct principle. 3.2 Clear It is more valuable to have code that other analysts can quickly understand, than code which runs a little quicker. Your work needs to be quality assured - so at least one other person will need to understand what you have written! Clarity is made up of many components (e.g. comments, easy to read code and data structures). But don’t overlook the clarity of your approach to the problem. Have you done something which will be impossible for someone else to check? Is there a more effective way to do it? 3.3 Fast You may find that you have produced code which takes some time to run. If you expect to run it many times, then its time to think about how you could make things faster. Don’t fall into the trap of optimising before you need to. For most languages there are profiling tools you can use to understand resource usage when you need to. 3.4 Concise Keeping the amount of code you use to achieve a goal at a minimum can often be a good thing. There is less code to go wrong or debug, less to explain, style and document. But, remember that concision is less important than correctness, clarity and speed. Don’t make it shorter than it needs to be, and think of the tradeoff with clarity and flexibility. "],
["flexible-code.html", "Principle 4 Write Flexible Code 4.1 Break up Your Code 4.2 Don’t Repeat Yourself 4.3 Input Validation 4.4 Structure 4.5 Error Handling", " Principle 4 Write Flexible Code Write flexible code where it will save time later. Good code is often adapted and repurposed. However, don’t try to solve every problem upfront, or try and cover edge cases you may never encounter. Find a balance and focus on making your code easy to change. You Must - Break up your code into chunks, with a clear structure and don’t repeat yourself. You Should - Think about, and document the way your code might break with different inputs. Include input validation to catch mistakes earlier in your code and make it easier to repurpose. You Could - Implement and test thorough error handling. Consider writing and sharing general purposes ‘tool’ code, especially if you solve a problem someone else might have. Related Areas: Comments Data Structure 4.1 Break up Your Code You should look to break up your code into chunks rather than working in a single long script or program. Each chunk of code should have a clear purpose. You can then use call on these chunks of code to build your analysis. There are many reasons to do this: It’s easier to see the structure of your code. It’s easier to make changes to your code. It’s easier to understand what has changed and what the effect is. You only have to document each chunk once. 4.2 Don’t Repeat Yourself Don’t Repeat Yourself is a common idea in programming. Instead of writing a bit of code several times to repeat an operation, you should re-use the same code by turning it into a function (or some other re-useable chunk - such as a method or subroutine). 4.3 Input Validation Think carefully about the input required for your code to work correctly: Data Type - Does the core require a specific class or type of input e.g. a number? Range - Does the value of a variable need to be in a certain range, e.g. between 0 - 1? Format - Does the code require the input to be in a particular format e.g. postcode? Size - Does your code assume a particular size of input e.g. &gt; 0 rows of data? Allowed Values - Is there a whitelist of valid input values to check against e.g. months? Building checks into your code for issues such as the above can make your code more robust. This will make it easier to repurpose with confidence in future. You may want to consider adding error handling to handle what happens if what these checks aren’t met. 4.4 Structure Think about the structure and sequence of your code. Keep inputs and key parameters that might need to change in a separate section which is easy to find. In some cases it may be appropriate to store such inputs in separate files which are read in, rather than storing them within the code. 4.5 Error Handling Its likely your code will be asked to do something you didn’t design it for, and it will break. You do know however what your code should be doing, what the input is expected to look like, and the properties of the output. You also probably have an idea of what your would like it to do when it doesn’t work correctly. You can use error or exception handling to control the errors and warnings that your code produces. This can allow you to and choose: Where your code breaks - by adding validation to a function input How your code breaks - by providing alternate code to be run in the event of an error. What it tells a user - by providing your own error messages which guide the user to a solution There are automated techniques such as fuzzing available to check how your code and error handling responds to different inputs. "],
["comments.html", "Principle 5 Comment Effectively 5.1 Comment Style 5.2 What to Capture 5.3 Alternatives", " Principle 5 Comment Effectively Comment your code so that it’s function is clear. Well targeted comments make it less likely that avoidable mistakes are made when using or updating your code. Colleagues and your future self will thank you. You Must - Write and maintain accurate comments as you code. You Should - Think carefully about why you are leaving comments, what to capture, and what belongs elsewhere (in documentation). You Could - Review old code you have written - are the comments helpful? What would you include next time? Related Areas: Documentation Easy to Read Code 5.1 Comment Style Use comments judiciously and look to your style guide for advice on how to comment. 5.2 What to Capture Ask yourself: “will I understand this code in a years time?” Comments should bridge the gap between the documentation and the code. They should be written in plain English and describe the logic and purpose of each chunk of code; i.e. where it fits in and why its there. 5.2.1 What not to Capture You don’t need to describe everything you are doing with the code in a comment. Someone reading the code should be literate in the language. Commenting extensively line by line makes it likely that code and comments will get out of sync when you go back and make changes. There should be separate documentation for high level questions such as the structure or logic of the analysis. Don’t write your plan or QA notes in the comments. Don’t store large chunks of alternate code in the comments. Leave that to your version control system. 5.3 Alternatives If you find yourself writing extensive comments, or writing more comments than code, consider changing format. There are options such as Jupyter Notebooks, and Rmarkdown for combining analysis and prose. "],
["documentation.html", "Principle 6 Document Your Work 6.1 Aqua Book Guidance for Technical Documentation: 6.2 Document as you Go 6.3 Use a Documentation Generator", " Principle 6 Document Your Work Maintain documentation for your code. Code is not self documenting and code without documentation won’t be useful later. You need to capture higher level context such as what the code is for, why it is written a certain way and what the inputs and outputs are. You Must - Produce documentation in line with Aqua book guidance. You Should - Assemble documentation as you code. You Could - Use document generation tools to produce documentation. Related Areas: Reproducibility Comments 6.1 Aqua Book Guidance for Technical Documentation: Pages 42-43 of the Aqua book contains guidance on documentation that should be in place as part of a quality assurance process for any analysis. The scope of the Aqua book is wider than code, however the definition of technical documentation is useful and repeated here: All analysis should have documentation for the user, even if that ‘user’ is just the analyst leading the analysis. This is to ensure that they have captured sufficient material to assist them if the analysis is revisited in due course. For analysis that is more likely to be revisited or updated in the future, documentation should be provided to assist a future analyst and should be more comprehensive. This documentation should include: a summary of the analysis including the context to the question being asked, what analytical methods were considered, what analysis was planned and why, what challenges were encountered and how they were overcome and what verification and validation steps were performed. In addition, guidance on what should be considered if the analysis is to be revisited or updated is beneficial. 6.2 Document as you Go Don’t fall into the trap of assuming documentation is something which is produced at the end. The best time to put together the documentation is as you are planning or doing the work - while it is fresh in your mind. This also means that switching projects wont result in undocumented work. 6.3 Use a Documentation Generator There are popular tools for generating documentation from your code and comments. These lighten the load of producing and publishing good documentation, and encourage you to produce thorough documentation. There are many documentation generators. Doxygen or Roxygen are recommended. "],
["demonstrably-correct.html", "Principle 7 Be Demonstrably Correct 7.1 Quality Assurance Applies to Code 7.2 Testing Frameworks 7.3 Version Control Integration 7.4 Reproducible Analytical Pipelines", " Principle 7 Be Demonstrably Correct Have a clear and robust way to demonstrate your code is correct. We need to be confident in the outputs we provide. Just because something is done with code doesn’t make it immune from answering the wrong question, using the wrong inputs, or doing the calculation incorrectly. You Must - Hold your code to the same standard as any other analysis and record evidence demonstrating it produces the right output. You Should - Use version control to unambiguously link QA to code and outputs and construct automated tests to provide confidence that changes don’t break things. You Could - Make a fully automated reproducible analytical pipeline (RAP) which incorporates checks and validation and minimises opportunity for human error. Related Areas: Version Control Be Reproducible 7.1 Quality Assurance Applies to Code Just because you have written code rather then making a spreadsheet doesnt mean your analysis is correct. Code is not exempt from Quality Assurance processes. As with any other analysis you need to record evidence that your code is: doing the right thing using valid inputs producing a sensible answer. You should refer to the Analytical Modelling Oversight Committee (AMOC) Quality Assurance (QA) materials which contain useful prompts and frameworks for quality assuring analysis of different size, importance and complexity. 7.2 Testing Frameworks Your code and analysis will grow and evolve. You wont have time to QA every version, and it can be tricky to keep track of which bits of QA have been made obsolete due to new or changed code. There are frameworks which help you construct and run tests on units of your code. These can be a good way to demonstrate that code is working correctly as you update it. See R at DHSC and Python at DHSC for more details. 7.3 Version Control Integration Having unit tests, and QA is good. Ideally however you can tie a particular result to a particular version of the QA’d and tested code. You could do this manually, by keeping the code for each set of outputs. Using git for version control makes this process easy. You can: Make a commit to the repository with a note like: output for XYZ on dd/mm/yy so you can identify the version used to produce outputs in future. Use tools such as gitpython or git2r to include the git commit hash which identifies the current version of the code in the output. This can then later be retrieved from your git repository. 7.4 Reproducible Analytical Pipelines Once you have some QA’d, version controlled and test covered code, the biggest source of error will be the manual steps performed by the analyst running it. You can eliminate a lot of this, see Reproducible Analytical Pipelines. "],
["sensible-defaults.html", "Principle 8 Use Sensible Defaults 8.1 General Defaults 8.2 Language Specific Defaults:", " Principle 8 Use Sensible Defaults Do common tasks in a consistent way, following guidance. If we use the same tools and approaches across the department, it makes collaboration and quality assurance easier. This is almost always more important than using the absolute best method. You Must - Be aware of the defaults, understand why we have them and follow them unless you can explain how the benefits of an alternative approach outweigh those of consistency. You Should - Help define what the defaults should be, and actively participate in discussion and debate to keep them up to date and relevant. You Could - Proactively review and compare the defaults used with the way you work. Related Areas: Easy to Read 8.1 General Defaults Use ‘Tidy’ data. See the tidy data principle! Use git for version control of code (rather than SVN, Mercurial etc). See the version control principle Use preexisting packages and code before writing your own. Use popular, mature and well supported packages in preference to up &amp; coming ones. 8.2 Language Specific Defaults: In addition to the general principles, please see the language specifc pages: Python at DHSC R at DHSC "],
["reproducible.html", "Principle 9 Be Reproducible 9.1 Unambiguous documentation for reproducibility 9.2 Portability 9.3 Project Structure 9.4 Reproducible Analytical Pipelines 9.5 Packages and Modules 9.6 Containers / Docker", " Principle 9 Be Reproducible Work in a way which is reproducible. Within the department, analysis is used to enable evidence based decision making. A piece of evidence which you cannot rely on being able to reproduce is not much good. There are many reproducibility pitfalls and it is our responsibility to overcome them. You Must - Keep track of what you have done and document it unambiguously so that someone else can recreate it. You Should - Write portable code, in a standard project structure so that it is easy for someone else to run it. You Could - Turn your code into a package / library / module, learn and promote RAP techniques, or use containers to achieve reproducibility. Related Areas: Demonstrably Correct Documentation 9.1 Unambiguous documentation for reproducibility To be able to reproduce your analysis a colleague may need the following: The right copy of the code The right versions of any dependencies (i.e. libraries used in the code) The platform on which code is run operating system folder structure machine specifications The source data, or details of how to get it. At the most basic level, documenting all of these will go a long way to making your analysis reproducible. It might not make it easy to reproduce however. 9.2 Portability There are some simple thing you can do to improve the chance that your code runs on other computers: Use relative paths, not absolute paths. (Wikipedia - Absolute and Relative Paths). Use a standard and consistent structure for organising your work. See Projects and Environments for more details. 9.3 Project Structure Most languages offer tools and templates for a project based workflow. Typically these include a way of organising the following components: Source Data Code Outputs Environment / Dependencies Documentation By following a standard template for these components you can take advantage of workflow tools provided by your IDE which make it easier to: Version Control your work Organise your code and source data Refactoring and improving your code Producing documentation Control your environment and dependencies All of these things are good for sharing or collaborating with others. See R at DHSC and Python at DHSC for more information, 9.4 Reproducible Analytical Pipelines There is a government community dedicated to the production of reproducible analysis. See Reproducible Analytical Pipelines for more. 9.5 Packages and Modules Most languages have a standard structure which is used to share code and documentation with other people. You will likely have used code in this structure (libraries / packages / modules) when performing your analysis. Typically these structures include documentation, information about dependencies, and tests. There is no reason you can’t use the same approach to sharing your analysis! See R at DHSC and Python at DHSC for more information, 9.6 Containers / Docker Containers allow you to manage the whole environment which a bit of code runs in. They are powerful but perhaps more technically involved than packaging your code or using project structures to manage your environment. Docker is a containerisation platform, which lets you reproduce environments with a wider scope than just the packages present. With Docker you can manage the entire environment from the operating system and network up (including any packages). You can use tools such as docker-compose and Kubernetes to manage groups of containers relative to one another. "],
["data-structure.html", "Principle 10 Use Appropriate and Tidy Data 10.1 Tidy Data? 10.2 Data Types and Structures 10.3 Schema", " Principle 10 Use Appropriate and Tidy Data Use the right data structures for the job. Programming languages offer many different ways to work with the same data. Using the right one will make a task easier, and decrease your chance of getting it wrong. You Must - Know what ‘Tidy Data’ is, and understand why it is valuable. You Should - Be familiar with the data types and structures available to you and ensure that you use the right ones. You Could - Think about relationships between datasets, design schemas and store data in an efficient way. Related Areas: Sensible Defaults 10.1 Tidy Data? A dataset is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways; every value belongs to a variable and an observation: A variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. An observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes. The majority of data we work with comes in rectangles. For this data to be tidy, ensure that: 1. Each variable forms a column. 2. Each observation forms a row. 3. Each type of observational unit forms a table. For more see the section on Tidy Data in R for Data Science or the original paper. Use tidy data structures as part of your work. You should attempt to convert incoming data into tidy format as quickly as possible. Any data that is output that may be used in other projects should be in tidy format as well as any other required formats. 10.2 Data Types and Structures Data types are the basic units which your language uses to store data, things like integers, doubles, strings and logical data. Typically you are working with data frames, arrays, matricies or lists. These hold multiple items of data in a data structure. Different types and structures are used for different things, and have different capabilities. To be effective, know about the data types and structures available to you and use the right ones for the job! 10.2.1 R The R Programming for Data Science book has a good section on the ‘Nuts and Bolts’ of R which covers types and structures. For more about the different data structures a good resource is the Advanced R book. 10.2.2 Python For a list of python datatypes see the: Python Documentation Pandas Documentation 10.3 Schema The R for data science book has a nice section on relational data. "],
["py-at-dhsc.html", "A Python at DHSC A.1 Version &amp; IDE A.2 Default Packages and Add Ins A.3 Project Workflow A.4 Packaging Your Code A.5 Managing Dependencies A.6 Unit Testing", " A Python at DHSC The following are the DHSC sensible defaults for Python: A.1 Version &amp; IDE Use Python 3 via Jupyter Notebooks or VSCode. A.2 Default Packages and Add Ins Use pandas for data analysis and reshaping Use loc and iloc to index into data frames Use Altair for basic data visualisation Use Scikit Learn for machine learning Use SQLAlchemy and pandas for database interactions, rather than writing your own SQL A.3 Project Workflow Python has many different options, all supported by different IDEs and tools: Anaconda &amp; Conda Projects - Getting started with Conda Pycharm Projects - Pycharm Projects A.4 Packaging Your Code Python - Packaging Projects A.5 Managing Dependencies Virtual Environments venv A.6 Unit Testing "],
["r-at-dhsc.html", "B R at DHSC B.1 R Version &amp; IDE B.2 Default Packages and Add Ins B.3 Project Workflow B.4 Packaging Your Code B.5 Managing Dependencies B.6 Unit Testing", " B R at DHSC The following are the DHSC sensible defaults for R: B.1 R Version &amp; IDE The dominant IDE for R is Rstudio, which comes packaged with R. For a new project you should use the latest version available from the software portal. B.2 Default Packages and Add Ins Default to packages from the Tidyverse, because they have been carefully designed to work together effectively as part of a modern data analysis workflow. More info can be found here: R for Data Science by Hadley Wickham. For example: Prefer tibbles to data.frames Use ggplot2 rather than base graphics Use the pipe %&gt;% rather than nesting function calls, but not always e.g. see here. Prefer purrr to the apply family of functions. See here B.3 Project Workflow Always work in a project. See the guide to Using Projects. Projects functionality is broken in DHSC’s packaged version of Rstudio - see the fix here: B.4 Packaging Your Code Packages are the fundamental unit of reproducible R code. Therefore, if possible, build an R Package to share and document your code. Hadley’s book on R Packages is an effective guide on how to produce a package. The usethis package has lots of useful shortcuts which. B.5 Managing Dependencies There are two key competing ways of managing dependencies for an R Project: packrat - current established way to renv - still maturing, successor to packrat See also: Rstudio page on managing environments in R Rbloggers post on renv Rstudio page on combining renv and docker B.6 Unit Testing Use the testthat package for performing unit tests. For details see the ‘tests’ chapter of R Packages. "],
["rap.html", "C Reproducible Analytical Pipelines C.1 Automating Pipelines C.2 Code version linked to outputs", " C Reproducible Analytical Pipelines Automating the steps used to create a your report or output is a good way to avoid the human errors that manual intervention will introduce. This is the focus of the Reproducible Analytical Pipelines community. The RAP community has curated the following resources: RAP Website Udemy Course C.1 Automating Pipelines You can do this by: Designing a final output which can be created without manual intervention. Making sure your code is broken down into chunks which do discrete tasks in your pipeline, for example: gathering cleaning processing and modelling reporting and visualisation Taking advantage of tools which keep track of the interactions between your data and code. These tools can then re-run the required bits of your pipeline automatically as you update, correct and improve it. GNU Make is the classic tool and is language agnostic, but perhaps not user friendly. The drake package is designed for analysis pipelines in R. The doit package can do the same and more for python. The python wiki also has a list of build tools for python. C.2 Code version linked to outputs You might successfully implement an automated pipeline and a reproducible environment. However unless you know which version of these was used to produce an output you might well come unstuck! Make sure that you can track backwards and determine which version of your code produced a particular output. You can do this by: Use git to version control your code Make ‘atomic’ commits which relate to individual Changes include the git hash (identifies the code) in the output R: git2r Python: gitpython "]
]
